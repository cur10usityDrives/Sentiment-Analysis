{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpftxH8OnjAfBOGBSJvzsU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cur10usityDrives/Sentiment-Analysis/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlAtG7Gi1vwY",
        "outputId": "e972b39f-cee5-4b01-e43b-25fabab8c2cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy (Unigram): 0.8616\n",
            "Validation Accuracy (Unigram + Bigram): 0.8846\n",
            "Test Accuracy (Best Model): 0.8934\n",
            "Top-10 Most Predictive Features: ['worst movie', 'waste of', 'waste your', 'waste', 'worst movies', 'don waste', 'worst film', 'the worst', 'worst', 'this crap']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Loading data using pandas read_csv function\n",
        "train_data = pd.read_csv(\"imdb_train.csv\")\n",
        "valid_data = pd.read_csv(\"imdb_valid.csv\")\n",
        "test_data = pd.read_csv(\"imdb_test.csv\")\n",
        "\n",
        "# Separate features and labels - assign the text column to X and labels to y\n",
        "X_train, y_train = train_data.iloc[:, 0], train_data.iloc[:, 1]\n",
        "X_valid, y_valid = valid_data.iloc[:, 0], valid_data.iloc[:, 1]\n",
        "X_test, y_test = test_data.iloc[:, 0], test_data.iloc[:, 1]\n",
        "\n",
        "# Vectorize text data using tfxidf for unigram features\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1))  # Unigram features\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_valid_tfidf = tfidf_vectorizer.transform(X_valid)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Train Naive Bayes classifier - MultinomialNB()\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Evaluate on validation set\n",
        "valid_accuracy = naive_bayes.score(X_valid_tfidf, y_valid)\n",
        "print(\"Validation Accuracy (Unigram):\", valid_accuracy)\n",
        "\n",
        "# Now, let's try with unigram + bigram features, still using tfxidf\n",
        "tfidf_vectorizer_ngram = TfidfVectorizer(ngram_range=(1, 2))  # Unigram + Bigram features\n",
        "X_train_tfidf_ngram = tfidf_vectorizer_ngram.fit_transform(X_train)\n",
        "X_valid_tfidf_ngram = tfidf_vectorizer_ngram.transform(X_valid)\n",
        "X_test_tfidf_ngram = tfidf_vectorizer_ngram.transform(X_test)\n",
        "\n",
        "# Train Naive Bayes classifier on uni+bigram vectorized X_train set - MultinomialNB()\n",
        "naive_bayes_ngram = MultinomialNB()\n",
        "naive_bayes_ngram.fit(X_train_tfidf_ngram, y_train)\n",
        "\n",
        "# Evaluate on validation set\n",
        "valid_accuracy_ngram = naive_bayes_ngram.score(X_valid_tfidf_ngram, y_valid)\n",
        "print(\"Validation Accuracy (Unigram + Bigram):\", valid_accuracy_ngram)\n",
        "\n",
        "# Choose the best model based on validation accuracy\n",
        "if valid_accuracy > valid_accuracy_ngram:\n",
        "    best_model = naive_bayes\n",
        "    best_vectorizer = tfidf_vectorizer\n",
        "else:\n",
        "    best_model = naive_bayes_ngram\n",
        "    best_vectorizer = tfidf_vectorizer_ngram\n",
        "\n",
        "# Evaluate the best model on the test set by vectorizing the test set using the best_vectorizer\n",
        "test_pred = best_model.predict(best_vectorizer.transform(X_test))\n",
        "test_accuracy = accuracy_score(y_test, test_pred)\n",
        "print(\"Test Accuracy (Best Model):\", test_accuracy)\n",
        "# Identify top-10 most predictive features based on absolute differences in log probabilities\n",
        "import numpy as np\n",
        "feature_names = best_vectorizer.get_feature_names_out()\n",
        "feature_probs = best_model.feature_log_prob_\n",
        "\n",
        "# Calculate absolute differences in log probabilities\n",
        "differences = np.abs(feature_probs[1] - feature_probs[0])\n",
        "\n",
        "# Sort features based on absolute differences\n",
        "top_10_indices = differences.argsort()[-10:][::-1]\n",
        "top_10_features = [feature_names[idx] for idx in top_10_indices]\n",
        "print(\"Top-10 Most Predictive Features:\", top_10_features)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify top-10 most predictive features\n",
        "feature_names = best_vectorizer.get_feature_names_out()\n",
        "# For MultinomialNB\n",
        "feature_probs = best_model.feature_log_prob_\n",
        "# Difference in log probabilities for positive vs. negative sentiment\n",
        "top_10_indices_pos = feature_probs[1] - feature_probs[0]\n",
        "top_10_indices_pos = top_10_indices_pos.argsort()[-10:][::-1]\n",
        "top_10_features_pos = [feature_names[feature] for feature in top_10_indices_pos]\n",
        "print(\"Top-10 Most Predictive Features for positive sentiment:\", top_10_features_pos)\n",
        "\n",
        "top_10_indices_neg = feature_probs[0] - feature_probs[1]\n",
        "top_10_indices_neg = top_10_indices_neg.argsort()[-10:][::-1]\n",
        "top_10_features_neg = [feature_names[feature] for feature in top_10_indices_neg]\n",
        "print(\"Top-10 Most Predictive Features for negative sentiment:\", top_10_features_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4twYzEdYo00",
        "outputId": "f76075db-9192-4237-f32b-52d4cab25394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-10 Most Predictive Features for positive sentiment: ['highly recommended', 'well worth', '10 10', 'loved this', 'is must', 'highly recommend', 'matthau', 'must see', 'definitely worth', 'loved it']\n",
            "Top-10 Most Predictive Features for negative sentiment: ['worst movie', 'waste of', 'waste your', 'waste', 'worst movies', 'don waste', 'worst film', 'the worst', 'worst', 'this crap']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify top-10 most predictive features based on absolute differences in log probabilities\n",
        "import numpy as np\n",
        "feature_names = best_vectorizer.get_feature_names_out()\n",
        "if hasattr(best_model, 'feature_log_prob_'):  # For MultinomialNB\n",
        "    feature_probs = best_model.feature_log_prob_\n",
        "else:  # For BernoulliNB or other classifiers\n",
        "    feature_probs = best_model.coef_\n",
        "\n",
        "# Calculate absolute differences in log probabilities\n",
        "differences = np.abs(feature_probs[1] - feature_probs[0])\n",
        "\n",
        "# Sort features based on absolute differences\n",
        "top_10_indices = differences.argsort()[-10:][::-1]\n",
        "top_10_features = [feature_names[idx] for idx in top_10_indices]\n",
        "print(\"Top-10 Most Predictive Features:\", top_10_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HueHodH3fIbJ",
        "outputId": "45606b92-4e0b-436f-8ee3-30570cf49140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-10 Most Predictive Features: ['worst movie', 'waste of', 'waste your', 'waste', 'worst movies', 'don waste', 'worst film', 'the worst', 'worst', 'this crap']\n"
          ]
        }
      ]
    }
  ]
}